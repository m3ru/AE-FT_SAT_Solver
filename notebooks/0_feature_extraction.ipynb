{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7eed8bc",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cee669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BENCHMARK_DIR = \"data/benchmarks/\"\n",
    "BENCHMARK_DIR = \"data/sample_cnf/\"\n",
    "\n",
    "# If notebook working dir is `notebooks/`, resolve BENCHMARK_DIR relative to repo root\n",
    "if not os.path.isabs(BENCHMARK_DIR):\n",
    "    repo_root_candidate = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "    candidate = os.path.join(repo_root_candidate, BENCHMARK_DIR)\n",
    "    if os.path.exists(candidate):\n",
    "        BENCHMARK_DIR = candidate\n",
    "    else:\n",
    "        BENCHMARK_DIR = os.path.abspath(BENCHMARK_DIR)\n",
    "\n",
    "OUTPUT_CSV = os.path.join(os.path.abspath(os.path.join(os.getcwd(), '..')), \"data\", \"features\", \"instance_features.csv\")\n",
    "print('Resolved BENCHMARK_DIR =', BENCHMARK_DIR)\n",
    "print('Will write OUTPUT_CSV =', OUTPUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1342bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify BENCHMARK_DIR and find .cnf files\n",
    "print('BENCHMARK_DIR =', repr(BENCHMARK_DIR))\n",
    "abs_dir = os.path.abspath(BENCHMARK_DIR)\n",
    "print('Absolute path =', abs_dir)\n",
    "pattern = os.path.join(BENCHMARK_DIR, '**', '*.cnf')\n",
    "matched = glob.glob(pattern, recursive=True)\n",
    "print(f'Found {len(matched)} .cnf files with pattern: {pattern}')\n",
    "for p in matched[:20]:\n",
    "    print(' -', p)\n",
    "\n",
    "print('Current working dir =', os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9114fff2",
   "metadata": {},
   "source": [
    "### Parse CNF header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cnf_header(cnf_path):\n",
    "    with open(cnf_path, 'r', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('p cnf'):\n",
    "                parts = line.split()\n",
    "                # p cnf <num_vars> <num_clauses>\n",
    "                n = int(parts[2])\n",
    "                m = int(parts[3])\n",
    "                return n, m\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be58a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "# search recursively for .cnf files under BENCHMARK_DIR\n",
    "for cnf_path in glob.glob(os.path.join(BENCHMARK_DIR, \"**\", \"*.cnf\"), recursive=True):\n",
    "    fname = os.path.basename(cnf_path)\n",
    "    n, m = parse_cnf_header(cnf_path)\n",
    "    if n is None or m is None:\n",
    "        print(f\"Warning: cannot parse header for {fname}\")\n",
    "        continue\n",
    "    ratio = m / n if n>0 else np.nan\n",
    "    \n",
    "    # Additional features: e.g., Horn clause fraction, literal balance\n",
    "    horn_count = 0      # number of Horn clauses\n",
    "    total_clauses = 0   # total number of clauses\n",
    "    pos_lits = 0        # total positive literals\n",
    "    neg_lits = 0        # total negative literals\n",
    "    clause_sizes = []\n",
    "    with open(cnf_path, 'r', errors='ignore') as f:\n",
    "        for raw in f:\n",
    "            line = raw.strip()\n",
    "            if not line or line.startswith('c') or line.startswith('p'):\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if not parts:\n",
    "                continue\n",
    "            lits = []\n",
    "            for x in parts:\n",
    "                if x == '0':\n",
    "                    break\n",
    "                if re.match(r'^-?\\d+$', x):\n",
    "                    lits.append(int(x))\n",
    "                else:\n",
    "                    # skip any non-integer token safely\n",
    "                    continue\n",
    "\n",
    "            if not lits:\n",
    "                continue\n",
    "            total_clauses += 1\n",
    "            clause_sizes.append(len(lits))\n",
    "            pos = sum(1 for l in lits if l>0)\n",
    "            neg = sum(1 for l in lits if l<0)\n",
    "            pos_lits += pos\n",
    "            neg_lits += neg\n",
    "            # Horn clause: at most one positive literal\n",
    "            if pos <= 1:\n",
    "                horn_count += 1\n",
    "\n",
    "    horn_frac = horn_count / total_clauses if total_clauses>0 else np.nan\n",
    "    pos_neg_balance = pos_lits / neg_lits if neg_lits>0 else np.nan\n",
    "    clause_size_mean = np.mean(clause_sizes) if clause_sizes else np.nan\n",
    "    clause_size_max = np.max(clause_sizes) if clause_sizes else np.nan\n",
    "    \n",
    "    rows.append({\n",
    "        \"instance\": fname,\n",
    "        \"num_vars\": n,\n",
    "        \"num_clauses\": m,\n",
    "        \"clause_var_ratio\": ratio,\n",
    "        \"horn_frac\": horn_frac,\n",
    "        \"pos_neg_balance\": pos_neg_balance,\n",
    "        \"clause_size_mean\": clause_size_mean,\n",
    "        \"clause_size_max\": clause_size_max\n",
    "    })\n",
    "\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "if not df.empty and 'instance' in df.columns:\n",
    "    df.set_index(\"instance\", inplace=True)\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"No instances were parsed â€” DataFrame is empty.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87deb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature\n",
    "out_dir = os.path.dirname(OUTPUT_CSV)\n",
    "if out_dir and not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "if 'df' in globals() and not df.empty:\n",
    "    df.to_csv(OUTPUT_CSV)\n",
    "    print(f\"Saved features to {OUTPUT_CSV}\")\n",
    "else:\n",
    "    print(\"No features to save (DataFrame missing or empty).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af928584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Histogram: clause/variable ratio\n",
    "plt.hist(df[\"clause_var_ratio\"].dropna(), bins=30)\n",
    "plt.title(\"Distribution of clause/variable ratio\")\n",
    "plt.xlabel(\"m/n\")\n",
    "plt.ylabel(\"Number of instances\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot: horn_frac vs clause_var_ratio\n",
    "plt.scatter(df[\"horn_frac\"], df[\"clause_var_ratio\"])\n",
    "plt.xlabel(\"Horn clause fraction\")\n",
    "plt.ylabel(\"Clause/var ratio\")\n",
    "plt.title(\"Horn frac vs clause/var ratio\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot: num_vars vs clause_var_ratio\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(df[\"num_vars\"], df[\"clause_var_ratio\"], alpha=0.7)\n",
    "plt.xlabel(\"Number of variables (n)\")\n",
    "plt.ylabel(\"Clause/variable ratio (m/n)\")\n",
    "plt.title(\"n vs m/n\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Colour-code by instance size category (small vs large)\n",
    "size_thresh = df[\"num_vars\"].median()\n",
    "plt.figure(figsize=(6,4))\n",
    "colors = [\"blue\" if n <= size_thresh else \"red\" for n in df[\"num_vars\"]]\n",
    "plt.scatter(df[\"num_vars\"], df[\"horn_frac\"], c=colors, alpha=0.7)\n",
    "plt.xlabel(\"Number of variables (n)\")\n",
    "plt.ylabel(\"Horn clause fraction\")\n",
    "plt.title(\"n vs horn_frac (blue=small, red=large)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Descriptive stats by size category\n",
    "small_df = df[df[\"num_vars\"] <= size_thresh]\n",
    "large_df = df[df[\"num_vars\"] > size_thresh]\n",
    "print(\"Small instances (<= {} vars):\".format(size_thresh))\n",
    "print(small_df.describe())\n",
    "print(\"\\nLarge instances (>= {} vars):\".format(size_thresh))\n",
    "print(large_df.describe())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
